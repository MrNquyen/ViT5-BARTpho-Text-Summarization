{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9562372",
   "metadata": {},
   "source": [
    "# SETUP DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0daf4-d225-44cb-b068-f1586d17ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bfd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ViInfographic-Summarization'...\n",
      "remote: Enumerating objects: 759, done.\u001b[K\n",
      "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
      "remote: Total 759 (delta 11), reused 35 (delta 10), pack-reused 711 (from 1)\u001b[K\n",
      "Receiving objects: 100% (759/759), 32.89 MiB | 26.64 MiB/s, done.\n",
      "Resolving deltas: 100% (459/459), done.\n",
      "Updating files: 100% (124/124), done.\n"
     ]
    }
   ],
   "source": [
    "user = \"MrNquyen\"\n",
    "token = \"\"\n",
    "repo = \"ViInfographic-Summarization\"\n",
    "\n",
    "!git clone --branch refactor https://{token}@github.com/{user}/{repo}.git\n",
    "!git clone https://github.com/MrNquyen/ViT5-BARTpho-Text-Summarization.git Simple-Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8638159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Seq2SeqTransformer-Text-Summarization' already exists and is not an empty directory.\n",
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "# Pycocoevalcap\n",
    "!git clone --branch bartpho_pycocoevalcap --single-branch https://github.com/MrNquyen/Seq2SeqTransformer-Text-Summarization.git\n",
    "!cp -r /kaggle/working/Seq2SeqTransformer-Text-Summarization/utils/pycocoevalcap /kaggle/working/Simple-Summarization/utils\n",
    "!cp -r /kaggle/working/ViInfographic-Summarization/data /kaggle/working/Simple-Summarization\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b3f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ViInfographic-Summarization\n",
      "mkdir: cannot create directory ‘./save’: File exists\n",
      "mkdir: cannot create directory ‘./save/log’: File exists\n",
      "mkdir: cannot create directory ‘./save/results’: File exists\n",
      "mkdir: cannot create directory ‘./save/checkpoints’: File exists\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Simple-Summarization\n",
    "\n",
    "# Save dir\n",
    "!mkdir ./save\n",
    "!mkdir ./save/log\n",
    "!mkdir ./save/results\n",
    "!mkdir ./save/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84edeb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (4/4), 407 bytes | 203.00 KiB/s, done.\n",
      "From https://github.com/MrNquyen/ViInfographic-Summarization\n",
      " * branch            refactor   -> FETCH_HEAD\n",
      "   41680e5..631dccd  refactor   -> origin/refactor\n",
      "Updating 41680e5..631dccd\n",
      "Fast-forward\n",
      " tools/ner_postag_annotate.py | 3 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
      " 1 file changed, 2 insertions(+), 1 deletion(-)\n"
     ]
    }
   ],
   "source": [
    "!git pull origin refactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacdd1b",
   "metadata": {},
   "source": [
    "# INSTALL PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6138eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: icecream in /usr/local/lib/python3.10/dist-packages (2.1.8)\n",
      "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (3.0.1)\n",
      "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.19.2)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from icecream) (0.4.6)\n",
      "Requirement already satisfied: executing>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: py_vncorenlp in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
      "Requirement already satisfied: pyjnius in /usr/local/lib/python3.10/dist-packages (from py_vncorenlp) (1.7.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install icecream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a254487c",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e0469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ViInfographic-Summarization\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Simple-Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ba513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Logger\n",
      "2026-01-02 09:30 - INFO - === START BUILDING ===\n",
      "2026-01-02 09:30 - INFO - === Build model params ===\n",
      "2026-01-02 09:30 - INFO - === Build model pretrained ===\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mmodel_name\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mvinai/bartpho-syllable\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "2026-01-02 09:30 - INFO - === Build model layers ===\n",
      "Loading train split: 100%|█████████████| 14186/14186 [00:00<00:00, 66203.28it/s]\n",
      "Loading val split: 100%|████████████████| 1773/1773 [00:00<00:00, 108770.07it/s]\n",
      "Loading test split: 100%|███████████████| 1773/1773 [00:00<00:00, 285865.34it/s]\n",
      "/workspace/ViInfographic-Summarization/utils/trainer.py:149: UserWarning: optimizer attributes has no params defined, defaulting to {}.\n",
      "  warnings.warn(\n",
      "Loading model from: pretrained_models/phonlp.pt\n",
      "2026-01-02 09:31:12 INFO  WordSegmenter:24 - Loading Word Segmentation model\n",
      "2026-01-02 09:31:12 INFO  DependencyParser:32 - Loading Dependency Parsing model\n",
      "2026-01-02 09:31 - INFO - === Model ===\n",
      "2026-01-02 09:31 - INFO - ViInfographicModel(\n",
      "  (encoder): MBartEncoder(\n",
      "    (embed_tokens): MBartScaledWordEmbedding(40030, 1024, padding_idx=1)\n",
      "    (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x MBartEncoderLayer(\n",
      "        (self_attn): MBartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): GELUActivation()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): MBartDecoder(\n",
      "    (embed_tokens): MBartScaledWordEmbedding(40030, 1024, padding_idx=1)\n",
      "    (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x MBartDecoderLayer(\n",
      "        (self_attn): MBartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): GELUActivation()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MBartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=40030, bias=False)\n",
      "  (viinfographic_encoder): ViInfographicEncoder(\n",
      "    (embed_tokens): MBartScaledWordEmbedding(40030, 1024, padding_idx=1)\n",
      "    (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x MBartEncoderLayer(\n",
      "        (self_attn): MBartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): GELUActivation()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (viinfographic_decoder): ViInfographicDecoder(\n",
      "    (decoder): MBartDecoder(\n",
      "      (embed_tokens): MBartScaledWordEmbedding(40030, 1024, padding_idx=1)\n",
      "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (viinfographic_classifier): Classifier(\n",
      "    (classifier): Linear(in_features=1024, out_features=40030, bias=False)\n",
      "  )\n",
      ")\n",
      "2026-01-02 09:31 - INFO - Starting training...\n",
      "Iterating through train loader: 0it [00:00, ?it/s]2026-01-02 09:31 - INFO - Training epoch: 1 - Batch: 1\n",
      "`use_cache=True` is incompatible with gradient checkpointing`. Setting `use_cache=False`...\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/workspace/ViInfographic-Summarization/utils/module_utils.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [torch.tensor(item), pad_post],\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 21.180225372314453, CE: 6.598906993865967, Contrastive: 14.581317901611328\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 1it [00:07,  7.13s/it]2026-01-02 09:31 - INFO - Training epoch: 1 - Batch: 2\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 22.41427230834961, CE: 6.816165924072266, Contrastive: 15.598105430603027\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 2it [00:10,  5.11s/it]2026-01-02 09:31 - INFO - Training epoch: 1 - Batch: 3\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 21.54957389831543, CE: 6.702169418334961, Contrastive: 14.847404479980469\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 3it [00:14,  4.29s/it]2026-01-02 09:31 - INFO - Training epoch: 1 - Batch: 4\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 22.07761001586914, CE: 6.793270111083984, Contrastive: 15.284339904785156\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 4it [00:19,  4.70s/it]2026-01-02 09:31 - INFO - Training epoch: 1 - Batch: 5\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 21.863658905029297, CE: 6.405342102050781, Contrastive: 15.4583158493042\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 5it [00:22,  4.18s/it]2026-01-02 09:31 - INFO - Training epoch: 1 - Batch: 6\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 21.00629425048828, CE: 6.39906644821167, Contrastive: 14.607227325439453\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 6it [00:26,  4.07s/it]2026-01-02 09:32 - INFO - Training epoch: 1 - Batch: 7\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 21.057491302490234, CE: 6.9640913009643555, Contrastive: 14.093399047851562\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 7it [00:30,  3.92s/it]2026-01-02 09:32 - INFO - Training epoch: 1 - Batch: 8\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 22.521793365478516, CE: 6.516046524047852, Contrastive: 16.005746841430664\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 8it [00:34,  4.02s/it]2026-01-02 09:32 - INFO - Training epoch: 1 - Batch: 9\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 21.635168075561523, CE: 6.572662353515625, Contrastive: 15.062505722045898\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 9it [00:38,  4.08s/it]2026-01-02 09:32 - INFO - Training epoch: 1 - Batch: 10\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36mf\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mTotal_loss: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mloss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, CE: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mce_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m, Contrastive: \u001b[39m\u001b[38;5;166m{\u001b[39m\u001b[38;5;247mcontrastive_loss_scalar\u001b[39m\u001b[38;5;166m}\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mTotal_loss: 22.01363754272461, CE: 6.497312545776367, Contrastive: 15.516324043273926\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "Iterating through train loader: 10it [00:42,  4.08s/it]2026-01-02 09:32 - INFO - Training epoch: 1 - Batch: 11\n"
     ]
    }
   ],
   "source": [
    "# !python3 main_bart.py --config ./config/config_bartpho_syllable.yaml --save_dir ./save --run_type train --device cuda\n",
    "!python3 main_t5.py --config ./config/config_vit5.yaml --save_dir ./save --run_type train --device cuda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
